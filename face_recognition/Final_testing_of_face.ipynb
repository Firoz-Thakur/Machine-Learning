{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview:\n",
    "\n",
    "# We have already detected the faces using haarscades  (done)\n",
    "\n",
    "    -1.Store the face information into numpy array.\n",
    "\n",
    "    -2. Flatten the largest face image and save in numpy array.\n",
    "\n",
    "    -3. Repeate the above for multiple people to generate training data and\n",
    "    store them all in the \"data\" file which having extension \".npy\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[252 160 163 163]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[243 158 171 171]]\n",
      "()\n",
      "()\n",
      "[[244 148 179 179]]\n",
      "[[244 148 179 179]]\n",
      "[[249 154 170 170]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[261 140 191 191]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[253 148 179 179]]\n",
      "[[253 148 179 179]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[228 147 188 188]]\n",
      "[[230 149 177 177]]\n",
      "[[221 145 188 188]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[230 138 196 196]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[251 140 201 201]]\n",
      "()\n",
      "[[267 142 191 191]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[267 141 200 200]]\n",
      "[[263 144 191 191]]\n",
      "()\n",
      "()\n",
      "[[266 141 196 196]]\n",
      "[[266 148 185 185]]\n",
      "[[266 146 188 188]]\n",
      "[[269 147 185 185]]\n",
      "[[269 147 185 185]]\n",
      "[[265 146 190 190]]\n",
      "[[266 143 194 194]]\n",
      "[[266 143 194 194]]\n",
      "()\n",
      "[[276 151 179 179]]\n",
      "[[276 151 179 179]]\n",
      "()\n",
      "()\n",
      "()\n",
      "[[266 144 191 191]]\n",
      "[[268 146 188 188]]\n",
      "[[268 146 185 185]]\n",
      "[[262 140 196 196]]\n",
      "[[265 146 188 188]]\n",
      "()\n",
      "()\n",
      "()\n",
      "[[260 138 198 198]]\n",
      "[[259 136 201 201]]\n",
      "[[252 134 205 205]]\n",
      "[[257 137 198 198]]\n",
      "[[257 137 198 198]]\n",
      "[[256 129 212 212]]\n",
      "[[264 137 196 196]]\n",
      "[[264 137 196 196]]\n",
      "[[261 134 198 198]]\n",
      "[[259 132 204 204]]\n",
      "[[258 136 200 200]]\n",
      "[[258 136 200 200]]\n",
      "()\n",
      "[[259 140 191 191]]\n",
      "[[258 139 194 194]]\n",
      "[[258 139 194 194]]\n",
      "[[255 137 199 199]]\n",
      "[[257 139 197 197]]\n",
      "[[256 137 201 201]]\n",
      "[[250 135 206 206]]\n",
      "()\n",
      "[[255 139 190 190]]\n",
      "[[255 139 190 190]]\n",
      "()\n",
      "[[258 140 188 188]]\n",
      "[[258 140 188 188]]\n",
      "[[255 145 188 188]]\n",
      "[[260 145 188 188]]\n",
      "[[258 143 188 188]]\n",
      "[[255 145 188 188]]\n",
      "[[256 143 185 185]]\n",
      "()\n",
      "()\n",
      "[[258 143 188 188]]\n",
      "[[261 147 179 179]]\n",
      "[[261 147 179 179]]\n",
      "[[259 142 188 188]]\n",
      "[[257 141 191 191]]\n",
      "[[257 141 191 191]]\n",
      "[[262 143 181 181]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[261 144 184 184]]\n",
      "[[261 144 184 184]]\n",
      "[[255 142 188 188]]\n",
      "[[262 139 188 188]]\n",
      "()\n",
      "()\n",
      "[[255 137 198 198]]\n",
      "[[255 137 198 198]]\n",
      "[[257 137 198 198]]\n",
      "[[256 138 194 194]]\n",
      "[[255 137 198 198]]\n",
      "[[259 139 192 192]]\n",
      "[[259 139 192 192]]\n",
      "[[262 139 188 188]]\n",
      "[[264 140 191 191]]\n",
      "[[262 138 191 191]]\n",
      "[[261 138 191 191]]\n",
      "[[268 147 181 181]]\n",
      "[[264 143 188 188]]\n",
      "[[266 143 184 184]]\n",
      "[[269 148 179 179]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[259 134 204 204]]\n",
      "[[255 132 212 212]]\n",
      "[[259 139 198 198]]\n",
      "[[261 139 191 191]]\n",
      "()\n",
      "[[265 142 188 188]]\n",
      "[[265 142 188 188]]\n",
      "[[266 140 188 188]]\n",
      "[[265 138 188 188]]\n",
      "()\n",
      "()\n",
      "[[269 145 181 181]]\n",
      "[[266 140 188 188]]\n",
      "[[267 139 194 194]]\n",
      "[[267 139 194 194]]\n",
      "[[264 140 188 188]]\n",
      "[[265 138 188 188]]\n",
      "[[265 138 188 188]]\n",
      "[[265 144 185 185]]\n",
      "[[267 143 191 191]]\n",
      "[[265 140 191 191]]\n",
      "[[270 146 178 178]]\n",
      "[[267 142 190 190]]\n",
      "()\n",
      "()\n",
      "[[267 145 184 184]]\n",
      "()\n",
      "()\n",
      "[[267 139 191 191]]\n",
      "[[262 130 204 204]]\n",
      "[[262 131 205 205]]\n",
      "[[262 131 205 205]]\n",
      "[[264 134 205 205]]\n",
      "[[265 133 200 200]]\n",
      "[[265 133 200 200]]\n",
      "[[267 134 200 200]]\n",
      "[[264 134 204 204]]\n",
      "[[265 133 205 205]]\n",
      "[[264 140 194 194]]\n",
      "()\n",
      "()\n",
      "[[240 134 205 205]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[241 144 191 191]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[245 138 204 204]]\n",
      "()\n",
      "()\n",
      "[[255 137 196 196]]\n",
      "[[261 144 191 191]]\n",
      "[[261 144 191 191]]\n",
      "[[258 139 194 194]]\n",
      "[[259 139 193 193]]\n",
      "[[257 138 197 197]]\n",
      "[[261 139 192 192]]\n",
      "[[261 139 192 192]]\n",
      "[[264 140 192 192]]\n",
      "[[263 140 194 194]]\n",
      "[[258 140 193 193]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#face detection\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    if ret==False:\n",
    "        continue\n",
    "    faces=face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    print(faces)\n",
    "    \n",
    "    for face in faces:\n",
    "        x,y,w,h=face\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    \n",
    "    key_pressed=cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# In the output we are geting the Frame dimension ,along with the online vedion stream\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the person : Firoz THakur\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "(47, 30000)\n",
      "Data successfully save at./data/Firoz THakur.npy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#face detection\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path='./data/'\n",
    "file_name=input(\"Enter the name of the person : \")\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    if ret==False:\n",
    "        continue\n",
    "    \n",
    "    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces=face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    faces=sorted(faces,key=lambda f:f[2]*f[3])\n",
    "    \n",
    "    #pick the last face( because it is the larges face acc to area(f(2) * f(3))\n",
    "    for face in faces[-1:]:\n",
    "        x,y,w,h=face\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        \n",
    "        #extract ( crop the required face): region of interst\n",
    "        offset=10\n",
    "        face_section=frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        face_section=cv2.resize(face_section,(100,100))\n",
    "        skip+=1\n",
    "        if skip%10==0:\n",
    "            face_data.append(face_section)\n",
    "            print(len(face_data))\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    #cv2.imshow(\"Face section\",face_section)\n",
    "    #stor every 10 face\n",
    "   \n",
    "   # cv2.imshow(\"face section\",face_section)\n",
    "\n",
    "    key_pressed=cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "#convert our face list arrray into nupy array\n",
    "face_data=np.asarray(face_data)\n",
    "face_data=face_data.reshape((face_data.shape[0],-1))\n",
    "print(face_data.shape)\n",
    "\n",
    "\n",
    "# save this data into file system\n",
    "\n",
    "np.save(dataset_path+file_name+'.npy',face_data)\n",
    "print(\"Data successfully save at\"+dataset_path+file_name+'.npy')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The previous says that 17 frame of the face have been saved in the file Firoz THakur.npy\n",
    "\n",
    "# Now, Testing Phase : -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Recognise Faces using some classification algorithm - like logistic ,KNN,SVM etc .\n",
    "\n",
    "# 2. Loaded the training  data ( numpy arrays of all the person )\n",
    "    - x - values are stored in the numpy arrays.\n",
    "    -y  - y-person we need stored in the  numpuy arrays.\n",
    "\n",
    "# 3. Use the KNN to find the prediction of face.\n",
    "\n",
    "# 4. Map the predicted ID to Name of user\n",
    "\n",
    "# 5. Display the prediction on the screen - bounding box and name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Algorithm to find the prediction of Face :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(v1,v2):\n",
    "    return np.sqrt(((v1-v2)**2).sum())\n",
    "\n",
    "\n",
    "def knn(train,test,k=5):\n",
    "    dist=[]\n",
    "    \n",
    "    for i in range(train.shape[0]):\n",
    "        # get the vector and label\n",
    "        ix=train[i,:-1]\n",
    "        iy=train[i,-1]\n",
    "        # compute the distance from the point\n",
    "        d=distance(test,ix)\n",
    "        dist.append([d,iy])\n",
    "        #sort based on distance and get top k\n",
    "    \n",
    "    dk=sorted(dist,key=lambda x:x[0])[:k]\n",
    "    \n",
    "    #retrieve only the labels\n",
    "    \n",
    "    labels=np.array(dk)[:,-1]\n",
    "    \n",
    "    #gett freq of each labels\n",
    "    \n",
    "    output=np.unique(labels,return_counts=True)\n",
    "    \n",
    "    #find max frq and corresponding label\n",
    "    index=np.argmax(output[1])\n",
    "    return output[0][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded abhi chotu.npy\n",
      "Loaded BoHemia sir.npy\n",
      "Loaded Chaman Lal.npy\n",
      "Loaded chinalo.npy\n",
      "Loaded diksha rana.npy\n",
      "Loaded FIROZ THakur.npy\n",
      "Loaded Firoz.npy\n",
      "Loaded golu.npy\n",
      "Loaded Kalpna Beta.npy\n",
      "Loaded Kamal Mehta.npy\n",
      "Loaded Kotta chinn.npy\n",
      "Loaded Monika Thakur.npy\n",
      "Loaded parekshit NiGa.npy\n",
      "Loaded Pritam vardhan.npy\n",
      "Loaded Rakesh Thakur.npy\n",
      "Loaded shanu.npy\n",
      "Loaded shubham bhai.npy\n",
      "Loaded sonu singh.npy\n",
      "(527, 30000)\n",
      "(527, 1)\n",
      "(527, 30001)\n",
      "Loaded abhi chotu.npy\n",
      "Loaded BoHemia sir.npy\n",
      "Loaded Chaman Lal.npy\n",
      "Loaded chinalo.npy\n",
      "Loaded diksha rana.npy\n",
      "Loaded FIROZ THakur.npy\n",
      "Loaded Firoz.npy\n",
      "Loaded golu.npy\n",
      "Loaded Kalpna Beta.npy\n",
      "Loaded Kamal Mehta.npy\n",
      "Loaded Kotta chinn.npy\n",
      "Loaded Monika Thakur.npy\n",
      "Loaded parekshit NiGa.npy\n",
      "Loaded Pritam vardhan.npy\n",
      "Loaded Rakesh Thakur.npy\n",
      "Loaded shanu.npy\n",
      "Loaded shubham bhai.npy\n",
      "Loaded sonu singh.npy\n",
      "(527, 30000)\n",
      "(527, 1)\n",
      "(527, 30001)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path='./data/'   \n",
    "labels=[]\n",
    "class_id=0\n",
    "names={}  # dic\n",
    "    \n",
    "#data preparation\n",
    "for fx in os.listdir(dataset_path):\n",
    "    \n",
    "    if fx.endswith('.npy'):\n",
    "        \n",
    "        #create a mapping btw classid and name\n",
    "        \n",
    "        names[class_id]=fx[:-4]\n",
    "        print(\"Loaded \"+fx)\n",
    "        data_item=np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "        \n",
    "        #create labels for the class\n",
    "        target=class_id*np.ones((data_item.shape[0],))\n",
    "        class_id+=1\n",
    "        labels.append(target)\n",
    "\n",
    "face_dataset=np.concatenate(face_data,axis=0)\n",
    "\n",
    "face_labels=np.concatenate(labels,axis=0).reshape((-1,1))\n",
    "print(face_dataset.shape)\n",
    "print(face_labels.shape)\n",
    "\n",
    "\n",
    "trainset=np.concatenate((face_dataset,face_labels),axis=1)\n",
    "print(trainset.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "cap=cv2.VideoCapture(0)\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path='./data/'    \n",
    "labels=[]\n",
    "class_id=0\n",
    "names={}\n",
    "    \n",
    "#data preparation\n",
    "\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('.npy'):\n",
    "        #create a mapping btw classid and name\n",
    "        names[class_id]=fx[:-4]\n",
    "        print(\"Loaded \"+fx)\n",
    "        data_item=np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "        \n",
    "        #create labels for the class\n",
    "        target=class_id*np.ones((data_item.shape[0],))\n",
    "        class_id+=1\n",
    "        labels.append(target)\n",
    "\n",
    "face_dataset=np.concatenate(face_data,axis=0)\n",
    "face_labels=np.concatenate(labels,axis=0).reshape((-1,1))\n",
    "print(face_dataset.shape)\n",
    "print(face_labels.shape)\n",
    "\n",
    "\n",
    "trainset=np.concatenate((face_dataset,face_labels),axis=1)\n",
    "print(trainset.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# testing : and calling to KNN         \n",
    "        \n",
    "while True:        \n",
    "        ret,frame=cap.read()\n",
    "        if ret==False:\n",
    "            continue\n",
    "        \n",
    "        faces=face_cascade.detectMultiScale(frame,1.3,5)\n",
    "\n",
    "\n",
    "        for face in faces:\n",
    "            x,y,w,h=face\n",
    "        \n",
    "            #get the face ROI\n",
    "            offset=10\n",
    "            face_section=frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "            face_section=cv2.resize(face_section,(100,100))\n",
    "        \n",
    "            #predicted label(out)\n",
    "            out=knn(trainset,face_section.flatten())\n",
    "        \n",
    "        #display on the screen the name rectangle around it\n",
    "        \n",
    "            pred_name=names[int(out)]\n",
    "            cv2.putText(frame,pred_name,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
    "    \n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    \n",
    "        cv2.imshow(\"Face\",frame)\n",
    "    \n",
    "        key=cv2.waitKey(1) & 0xff\n",
    "        if key==ord('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](baba11.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the system for different input faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[click here to watch the vedio of output result](https://drive.google.com/file/d/151HoxxH8-s2d7s0_g2uaw_-LQuBbEsvg/view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
