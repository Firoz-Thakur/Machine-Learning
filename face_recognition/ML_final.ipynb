{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded abhi chotu.npy\n",
      "Loaded BoHemia sir.npy\n",
      "Loaded Chaman Lal.npy\n",
      "Loaded chinalo.npy\n",
      "Loaded diksha rana.npy\n",
      "Loaded Firoz.npy\n",
      "Loaded golu.npy\n",
      "Loaded Kalpna Beta.npy\n",
      "Loaded Kamal Mehta.npy\n",
      "Loaded Kotta chinn.npy\n",
      "Loaded Monika Thakur.npy\n",
      "Loaded parekshit NiGa.npy\n",
      "Loaded Pritam vardhan.npy\n",
      "Loaded Rakesh Thakur.npy\n",
      "Loaded shanu.npy\n",
      "Loaded shubham bhai.npy\n",
      "Loaded sonu singh.npy\n",
      "(490, 30000)\n",
      "(490, 1)\n",
      "(490, 30001)\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "########################## KNN code###################\n",
    "\n",
    "def distance(v1,v2):\n",
    "    return np.sqrt(((v1-v2)**2).sum())\n",
    "\n",
    "\n",
    "def knn(train,test,k=5):\n",
    "    dist=[]\n",
    "    \n",
    "    for i in range(train.shape[0]):\n",
    "        # get the vector and label\n",
    "        ix=train[i,:-1]\n",
    "        iy=train[i,-1]\n",
    "        # compute the distance from the point\n",
    "        d=distance(test,ix)\n",
    "        dist.append([d,iy])\n",
    "        #sort based on distance and get top k\n",
    "    \n",
    "    dk=sorted(dist,key=lambda x:x[0])[:k]\n",
    "    \n",
    "    #retrieve only the labels\n",
    "    \n",
    "    labels=np.array(dk)[:,-1]\n",
    "    \n",
    "    #gett freq of each labels\n",
    "    \n",
    "    output=np.unique(labels,return_counts=True)\n",
    "    \n",
    "    #find max frq and corresponding label\n",
    "    index=np.argmax(output[1])\n",
    "    return output[0][index]\n",
    "\n",
    "########################## KNN end####################     \n",
    "cap=cv2.VideoCapture(0)\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path='./data/'    \n",
    "labels=[]\n",
    "class_id=0\n",
    "names={}\n",
    "    \n",
    "#data preparation\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('.npy'):\n",
    "        #create a mapping btw classid and name\n",
    "        names[class_id]=fx[:-4]\n",
    "        print(\"Loaded \"+fx)\n",
    "        data_item=np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "        \n",
    "        #create labels for the class\n",
    "        target=class_id*np.ones((data_item.shape[0],))\n",
    "        class_id+=1\n",
    "        labels.append(target)\n",
    "\n",
    "face_dataset=np.concatenate(face_data,axis=0)\n",
    "face_labels=np.concatenate(labels,axis=0).reshape((-1,1))\n",
    "print(face_dataset.shape)\n",
    "print(face_labels.shape)\n",
    "\n",
    "\n",
    "trainset=np.concatenate((face_dataset,face_labels),axis=1)\n",
    "print(trainset.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # testing        \n",
    "        \n",
    "while True:        \n",
    "        ret,frame=cap.read()\n",
    "        if ret==False:\n",
    "            continue\n",
    "        \n",
    "        faces=face_cascade.detectMultiScale(frame,1.3,5)\n",
    "\n",
    "\n",
    "        for face in faces:\n",
    "            x,y,w,h=face\n",
    "        \n",
    "            #get the face ROI\n",
    "            offset=10\n",
    "            face_section=frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "            face_section=cv2.resize(face_section,(100,100))\n",
    "        \n",
    "            #predicted label(out)\n",
    "            out=knn(trainset,face_section.flatten())\n",
    "        \n",
    "        #display on the screen the name rectangle around it\n",
    "        \n",
    "            pred_name=names[int(out)]\n",
    "            cv2.putText(frame,pred_name,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
    "    \n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    \n",
    "        cv2.imshow(\"Face\",frame)\n",
    "    \n",
    "        key=cv2.waitKey(1) & 0xff\n",
    "        if key==ord('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the person : sonu singh\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "(27, 30000)\n",
      "Data successfully save at./data/sonu singh.npy\n"
     ]
    }
   ],
   "source": [
    "#storing the data\n",
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#face detection\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path='./data/'\n",
    "file_name=input(\"Enter the name of the person : \")\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    if ret==False:\n",
    "        continue\n",
    "    \n",
    "    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces=face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    faces=sorted(faces,key=lambda f:f[2]*f[3])\n",
    "    \n",
    "    #pick the last face( because it is the larges face acc to area(f(2) * f(3))\n",
    "    for face in faces[-1:]:\n",
    "        x,y,w,h=face\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        \n",
    "        #extract ( crop the required face): region of interst\n",
    "        offset=10\n",
    "        face_section=frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        face_section=cv2.resize(face_section,(100,100))\n",
    "        skip+=1\n",
    "        if skip%10==0:\n",
    "            face_data.append(face_section)\n",
    "            print(len(face_data))\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    #cv2.imshow(\"Face section\",face_section)\n",
    "    #stor every 10 face\n",
    "   \n",
    "   # cv2.imshow(\"face section\",face_section)\n",
    "\n",
    "    key_pressed=cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "#convert our face list arrray into nupy array\n",
    "face_data=np.asarray(face_data)\n",
    "face_data=face_data.reshape((face_data.shape[0],-1))\n",
    "print(face_data.shape)\n",
    "\n",
    "\n",
    "# save this data into file system\n",
    "\n",
    "np.save(dataset_path+file_name+'.npy',face_data)\n",
    "print(\"Data successfully save at\"+dataset_path+file_name+'.npy')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
