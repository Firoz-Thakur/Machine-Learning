{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview:\n",
    "\n",
    "# We have already detected the faces using haarscades)(done)\n",
    "\n",
    "    -1.Store the face information into numpy array.\n",
    "\n",
    "    -2. Flatten the largest face image and save in numpy array.\n",
    "\n",
    "    -3. Repeate the above for multiple people to generate training data and\n",
    "    store them all in the \"data\" file which having extension \".npy\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[244 132 163 163]]\n",
      "[[244 119 169 169]]\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "[[252 120 170 170]]\n",
      "()\n",
      "[[251 126 163 163]]\n",
      "[[251 124 163 163]]\n",
      "[[251 124 163 163]]\n",
      "[[249 124 170 170]]\n",
      "[[249 124 170 170]]\n",
      "[[250 121 168 168]]\n",
      "[[254 123 163 163]]\n",
      "[[254 123 163 163]]\n",
      "[[255 128 163 163]]\n",
      "[[255 118 173 173]]\n",
      "[[255 118 173 173]]\n",
      "[[253 119 173 173]]\n",
      "[[258 121 170 170]]\n",
      "[[258 121 170 170]]\n",
      "[[258 120 171 171]]\n",
      "[[257 118 173 173]]\n",
      "[[257 118 173 173]]\n",
      "[[258 115 177 177]]\n",
      "[[258 115 177 177]]\n",
      "()\n",
      "[[258 118 175 175]]\n",
      "[[258 118 175 175]]\n",
      "()\n",
      "[[256 114 181 181]]\n",
      "[[259 115 178 178]]\n",
      "[[259 115 178 178]]\n",
      "[[254 114 188 188]]\n",
      "[[260 120 171 171]]\n",
      "[[264 120 165 165]]\n",
      "[[259 117 177 177]]\n",
      "[[260 116 177 177]]\n",
      "[[267 122 157 157]]\n",
      "[[268 122 157 157]]\n",
      "[[268 122 157 157]]\n",
      "[[266 122 163 163]]\n",
      "[[259 116 175 175]]\n",
      "()\n",
      "[[260 120 171 171]]\n",
      "[[258 118 171 171]]\n",
      "()\n",
      "()\n",
      "[[264 119 164 164]]\n",
      "[[261 119 170 170]]\n",
      "()\n",
      "()\n",
      "[[262 119 170 170]]\n",
      "[[260 118 175 175]]\n",
      "[[264 121 171 171]]\n",
      "[[262 119 171 171]]\n",
      "()\n",
      "[[266 120 170 170]]\n",
      "[[266 120 170 170]]\n",
      "[[268 125 163 163]]\n",
      "[[268 124 163 163]]\n",
      "[[267 122 163 163]]\n",
      "[[263 115 174 174]]\n",
      "()\n",
      "()\n",
      "[[263 122 163 163]]\n",
      "[[261 119 169 169]]\n",
      "[[264 124 163 163]]\n",
      "[[263 122 163 163]]\n",
      "[[265 122 163 163]]\n",
      "[[264 124 163 163]]\n",
      "[[262 123 164 164]]\n",
      "[[263 122 163 163]]\n",
      "[[260 120 171 171]]\n",
      "[[260 118 173 173]]\n",
      "[[260 118 173 173]]\n",
      "[[257 120 173 173]]\n",
      "[[260 116 175 175]]\n",
      "[[260 120 168 168]]\n",
      "[[262 120 168 168]]\n",
      "[[262 120 168 168]]\n",
      "[[256 116 179 179]]\n",
      "[[262 123 163 163]]\n",
      "[[262 123 163 163]]\n",
      "[[260 120 168 168]]\n",
      "[[256 116 179 179]]\n",
      "[[260 121 168 168]]\n",
      "[[263 122 163 163]]\n",
      "[[261 119 169 169]]\n",
      "[[258 120 169 169]]\n",
      "[[265 122 163 163]]\n",
      "[[263 122 163 163]]\n",
      "[[263 122 163 163]]\n",
      "[[263 122 163 163]]\n",
      "[[264 124 163 163]]\n",
      "[[264 124 163 163]]\n",
      "[[256 120 173 173]]\n",
      "[[262 125 163 163]]\n",
      "[[263 122 163 163]]\n",
      "[[261 120 169 169]]\n",
      "[[258 119 174 174]]\n",
      "[[258 119 174 174]]\n",
      "[[261 120 169 169]]\n",
      "[[262 125 163 163]]\n",
      "[[259 117 174 174]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#face detection\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    if ret==False:\n",
    "        continue\n",
    "    faces=face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    print(faces)\n",
    "    \n",
    "    for face in faces:\n",
    "        x,y,w,h=face\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    \n",
    "    key_pressed=cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# In the output we are geting the Frame dimension ,along with the online vedion stream\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the person : FIROZ THakur\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "(17, 30000)\n",
      "Data successfully save at./data/FIROZ THakur.npy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "#face detection\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "skip=0\n",
    "face_data=[]\n",
    "dataset_path='./data/'\n",
    "file_name=input(\"Enter the name of the person : \")\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    if ret==False:\n",
    "        continue\n",
    "    \n",
    "    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces=face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    faces=sorted(faces,key=lambda f:f[2]*f[3])\n",
    "    \n",
    "    #pick the last face( because it is the larges face acc to area(f(2) * f(3))\n",
    "    for face in faces[-1:]:\n",
    "        x,y,w,h=face\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        \n",
    "        #extract ( crop the required face): region of interst\n",
    "        offset=10\n",
    "        face_section=frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        face_section=cv2.resize(face_section,(100,100))\n",
    "        skip+=1\n",
    "        if skip%10==0:\n",
    "            face_data.append(face_section)\n",
    "            print(len(face_data))\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    #cv2.imshow(\"Face section\",face_section)\n",
    "    #stor every 10 face\n",
    "   \n",
    "   # cv2.imshow(\"face section\",face_section)\n",
    "\n",
    "    key_pressed=cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "#convert our face list arrray into nupy array\n",
    "face_data=np.asarray(face_data)\n",
    "face_data=face_data.reshape((face_data.shape[0],-1))\n",
    "print(face_data.shape)\n",
    "\n",
    "\n",
    "# save this data into file system\n",
    "\n",
    "np.save(dataset_path+file_name+'.npy',face_data)\n",
    "print(\"Data successfully save at\"+dataset_path+file_name+'.npy')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The previous says that 17 frame of the face have been saved in the file Firoz THakur.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
